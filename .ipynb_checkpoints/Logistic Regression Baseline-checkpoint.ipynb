{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [\n",
    "\t{\"id\": \"1-800-flowers\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Alfred Sung\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Alibaba\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Amazon\", \"count\" : 18,\"label\" : 1},\n",
    "\t{\"id\": \"American Apparel\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Arngren\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Azteca Soccer\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Best Electronic\", \"count\" : 17,\"label\" : 0},\n",
    "\t{\"id\": \"BestBuy\", \"count\" : 18,\"label\" : 1},\n",
    "\t{\"id\": \"BigCommerce\", \"count\" : 18,\"label\" : 1},\n",
    "\t{\"id\": \"Blinkee\", \"count\" : 16,\"label\" : 0},\n",
    "\t{\"id\": \"Bliss\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"BonBonBon\", \"count\" : 19,\"label\" : 1},\n",
    "\t{\"id\": \"Costco\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"CruiseMaster\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Custom Barres\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"CVS\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Decibullz\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"DSW\", \"count\" : 16,\"label\" : 0},\n",
    "\t{\"id\": \"eBay\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"Electrifying Times\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Fanatics\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Flipkart\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Footlocker\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Free City Supershop\", \"count\" : 11,\"label\" : 0},\n",
    "\t{\"id\": \"H & M\", \"count\" : 19,\"label\" : 0},\n",
    "\t{\"id\": \"Home Science Tools\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Ikea\", \"count\" : 16,\"label\" : 0},\n",
    "\t{\"id\": \"Jabong\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Jeep People\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Koi Computer\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Lazada\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"Ling's Cars\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Mednat\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Mercia Tourist Board\", \"count\" : 12,\"label\" : 0},\n",
    "\t{\"id\": \"Microcenter.com\", \"count\" : 18, \"label\" : 0},\n",
    "\t{\"id\": \"Next Chapter\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Nordstrom\", \"count\" : 16,\"label\" : 0},\n",
    "\t{\"id\": \"Opensky\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"P & M Computers\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Paradise With A View\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Pennyjuice\", \"count\" : 12,\"label\" : 0},\n",
    "\t{\"id\": \"Rakuten\", \"count\" : 19,\"label\" : 0},\n",
    "\t{\"id\": \"RalphLauren.com\", \"count\" : 19,\"label\" : 0},\n",
    "\t{\"id\": \"Renogy\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"Rusty Surfboards\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Shopee\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"Shopify\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Signal Boosters\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Skullcandy\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"SnapDeal\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Suzanne Collins Books\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"The Mountain\", \"count\" : 18,\"label\" : 1},\n",
    "\t{\"id\": \"True Links Wear\", \"count\" : 16,\"label\" : 1},\n",
    "\t{\"id\": \"Urban Outfitters\", \"count\" : 15,\"label\" : 0},\n",
    "\t{\"id\": \"Walgreens\", \"count\" : 16,\"label\" : 0},\n",
    "\t{\"id\": \"Walmart\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Water Equipment\", \"count\" : 18,\"label\" : 0},\n",
    "\t{\"id\": \"Woocommerce\", \"count\" : 15,\"label\" : 1},\n",
    "\t{\"id\": \"Zalora\", \"count\" : 16,\"label\" : 1}   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = [[] for i in range(5)]\n",
    "good = [x for x in sites if x[\"label\"] == 1]\n",
    "bad = [x for x in sites if x[\"label\"] == 0]\n",
    "shuffle(good)\n",
    "shuffle(bad)\n",
    "for i in range(30):\n",
    "    folds[i//6].append(good[i])\n",
    "    folds[i//6].append(bad[i])\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Fold\",i);\n",
    "    for j in folds[i]:\n",
    "        print(j[\"id\"],j[\"count\"],j[\"label\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [[] for i in range(5)]\n",
    "# labels = [[] for i in range(5)]\n",
    "# sum = 0\n",
    "# for i in range(0,5):\n",
    "#     for site in folds[i]:\n",
    "#         sum += site[\"count\"]\n",
    "#         for j in range(1,site['count'] + 1):\n",
    "# #         for i in range(1,2):\n",
    "#             labels[i] = labels[i] + [site[\"label\"]]\n",
    "#             temp = PIL.Image.open(\"%s/%s - %02d.png\" % (site['id'],site['id'],j))\n",
    "#             temp = np.array(temp);\n",
    "#             temp = resize(temp, (temp.shape[0] // 2, temp.shape[1] // 2), anti_aliasing=True)\n",
    "#             data[i].append(temp)\n",
    "#             print(\"Loading %s/%s - %02d.png\" % (site['id'],site['id'],j))\n",
    "# print(\"Loaded %d screens.\" % sum)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data.pt', 'wb') as f:\n",
    "#     pickle.dump(data, f)\n",
    "    \n",
    "# with open('labels.pt', 'wb') as f:\n",
    "#     pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labels.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(786816,2)\n",
    "#         self.linear = torch.nn.Linear(1,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "#         print(x.shape)\n",
    "        out = F.sigmoid(self.linear(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(786816, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = X.view(X.size(0), -1)\n",
    "        out = self.dropout(torch.relu(self.fc1(out)))\n",
    "        out = self.dropout(torch.relu(self.fc2(out)))\n",
    "        out = self.dropout(torch.relu(self.fc3(out)))\n",
    "        out = torch.log_softmax(self.fc4(out), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = d + data[i];\n",
    "                l = l + labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_out, 1)[1] == y).item() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        print(i,s)\n",
    "            \n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_out, 1)[1] == y).item() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for i, s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(hidden_dim=256, dropout=0.3).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.1)\n",
    "#amp_handle.wrap_optimizer(optimizer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#amp_handle = amp.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5dc9b855455a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                             shuffle=True)\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mvloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_test_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdlosscurve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-29707500fb5d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, crit, opt, dataload, disable)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "batch_size = 32\n",
    "disable = False\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    dlosscurve = []\n",
    "    dacccurve = []\n",
    "    vlosscurve = []\n",
    "    vacccurve = []\n",
    "    print(\"Fold %d\" % (i + 1))\n",
    "    my_data.setTest(i)\n",
    "    my_test.setTest(i)\n",
    "    \n",
    "    my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    for j in range(epochs):\n",
    "        dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "        vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "        dlosscurve.append(dloss)\n",
    "        dacccurve.append(dacc)\n",
    "        vlosscurve.append(vloss)\n",
    "        vacccurve.append(vacc)\n",
    "        if j % 10 == 0:\n",
    "            print(j,dloss,dacc,vloss,vacc)\n",
    "    df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "    df.plot.line()\n",
    "    avedloss += dloss\n",
    "    avedacc += dacc\n",
    "    avevloss += vloss\n",
    "    avevacc += vacc\n",
    "avedloss /= 5\n",
    "avedacc /= 5\n",
    "avevloss /= 5\n",
    "avevacc /= 5\n",
    "print(\"Average Train Loss: %.6f\\nAverage Train Accuracy: %.6f\\nAverage Test Loss: %.6f\\nAverage Test Accuracy: %.6f\\n\" % (avedloss,avedacc,avevloss,avevacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
