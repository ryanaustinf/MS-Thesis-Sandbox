{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataconvall.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labelsall.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "    \n",
    "with open('datavalconvall.pt', 'rb') as f:\n",
    "    dataVal = pickle.load(f)\n",
    "    \n",
    "with open('labelsval.pt', 'rb') as f:\n",
    "    labelsVal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self,dropout=0.5):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3)\n",
    "        self.conv62 = nn.Conv2d(256, 256, kernel_size=3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3)\n",
    "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3,padding=1)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(1536,4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 4)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv1(x)))\n",
    "        x = self.dropout(torch.relu(self.conv2(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv3(x)))\n",
    "        x = self.dropout(torch.relu(self.conv4(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv5(x)))\n",
    "        x = self.dropout(torch.relu(self.conv6(x)))\n",
    "        x = self.dropout(torch.relu(self.conv62(x)))\n",
    "        x = self.dropout(torch.relu(self.conv62(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv7(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.mp(x)\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True,isVal=False):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.isVal = isVal\n",
    "        if isVal:\n",
    "            self.testX = torch.from_numpy(np.asarray(data,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "            self.testY = torch.from_numpy(np.asarray(labels,dtype=np.uint8)).type('torch.LongTensor')\n",
    "        else:\n",
    "            self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        if self.isVal:\n",
    "            d = self.data\n",
    "            l = self.labels\n",
    "            self.testX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "            self.testY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "            return\n",
    "        d = np.empty((0,3,384,683),int)\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = np.append(d,self.data[i],axis=0)\n",
    "                l += self.labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc\n",
    "\n",
    "def test_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 18\n",
      "Weight Decay: 0.5810997433816847\n",
      "Dropout: 0.31165035374669575\n",
      "\n",
      "Fold 1\n",
      "Epoch Train Loss: 1.294412  Epoch Train Accuracy: 49.027778  Epoch Test Loss: 1.289876  Epoch Test Accuracy: 50.811966\n",
      "Epoch Train Loss: 1.224998  Epoch Train Accuracy: 49.010417  Epoch Test Loss: 1.221978  Epoch Test Accuracy: 50.811966\n",
      "Epoch Train Loss: 1.179904  Epoch Train Accuracy: 48.993056  Epoch Test Loss: 1.178114  Epoch Test Accuracy: 49.957265\n",
      "Epoch Train Loss: 1.153467  Epoch Train Accuracy: 50.989583  Epoch Test Loss: 1.152518  Epoch Test Accuracy: 50.470085\n",
      "Epoch Train Loss: 1.139685  Epoch Train Accuracy: 50.954861  Epoch Test Loss: 1.139388  Epoch Test Accuracy: 49.401709\n",
      "Epoch Train Loss: 1.133290  Epoch Train Accuracy: 50.989583  Epoch Test Loss: 1.133326  Epoch Test Accuracy: 49.401709\n",
      "Epoch Train Loss: 1.130522  Epoch Train Accuracy: 51.041667  Epoch Test Loss: 1.130719  Epoch Test Accuracy: 49.401709\n",
      "Epoch Train Loss: 1.129322  Epoch Train Accuracy: 50.954861  Epoch Test Loss: 1.129431  Epoch Test Accuracy: 50.042735\n",
      "Epoch Train Loss: 1.128684  Epoch Train Accuracy: 50.954861  Epoch Test Loss: 1.128758  Epoch Test Accuracy: 50.470085\n",
      "Epoch Train Loss: 1.128369  Epoch Train Accuracy: 50.972222  Epoch Test Loss: 1.128534  Epoch Test Accuracy: 50.042735\n",
      "Fold 2\n",
      "Epoch Train Loss: 1.293677  Epoch Train Accuracy: 49.572650  Epoch Test Loss: 1.289614  Epoch Test Accuracy: 47.986111\n",
      "Epoch Train Loss: 1.224101  Epoch Train Accuracy: 49.626068  Epoch Test Loss: 1.221435  Epoch Test Accuracy: 47.777778\n",
      "Epoch Train Loss: 1.179129  Epoch Train Accuracy: 49.732906  Epoch Test Loss: 1.177424  Epoch Test Accuracy: 47.777778\n",
      "Epoch Train Loss: 1.152706  Epoch Train Accuracy: 47.489316  Epoch Test Loss: 1.151700  Epoch Test Accuracy: 52.430556\n",
      "Epoch Train Loss: 1.139042  Epoch Train Accuracy: 50.373932  Epoch Test Loss: 1.138500  Epoch Test Accuracy: 52.083333\n",
      "Epoch Train Loss: 1.132923  Epoch Train Accuracy: 50.267094  Epoch Test Loss: 1.132621  Epoch Test Accuracy: 52.083333\n",
      "Epoch Train Loss: 1.130359  Epoch Train Accuracy: 50.320513  Epoch Test Loss: 1.130157  Epoch Test Accuracy: 52.152778\n",
      "Epoch Train Loss: 1.129255  Epoch Train Accuracy: 50.373932  Epoch Test Loss: 1.129070  Epoch Test Accuracy: 52.222222\n",
      "Epoch Train Loss: 1.128741  Epoch Train Accuracy: 50.267094  Epoch Test Loss: 1.128562  Epoch Test Accuracy: 52.222222\n",
      "Epoch Train Loss: 1.128459  Epoch Train Accuracy: 50.267094  Epoch Test Loss: 1.128271  Epoch Test Accuracy: 52.361111\n",
      "Fold 3\n",
      "Epoch Train Loss: 1.293451  Epoch Train Accuracy: 48.888889  Epoch Test Loss: 1.289001  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.223723  Epoch Train Accuracy: 49.166667  Epoch Test Loss: 1.220791  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.178841  Epoch Train Accuracy: 49.305556  Epoch Test Loss: 1.177076  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.152640  Epoch Train Accuracy: 51.111111  Epoch Test Loss: 1.151752  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.139109  Epoch Train Accuracy: 50.972222  Epoch Test Loss: 1.138764  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.132891  Epoch Train Accuracy: 51.250000  Epoch Test Loss: 1.132836  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.130234  Epoch Train Accuracy: 51.250000  Epoch Test Loss: 1.131013  Epoch Test Accuracy: 45.959596\n",
      "Epoch Train Loss: 1.129165  Epoch Train Accuracy: 50.833333  Epoch Test Loss: 1.128459  Epoch Test Accuracy: 54.040404\n",
      "Epoch Train Loss: 1.128624  Epoch Train Accuracy: 50.972222  Epoch Test Loss: 1.128761  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 1.128323  Epoch Train Accuracy: 50.972222  Epoch Test Loss: 1.128490  Epoch Test Accuracy: 50.000000\n",
      "Fold 4\n",
      "Epoch Train Loss: 1.294003  Epoch Train Accuracy: 49.404762  Epoch Test Loss: 1.289832  Epoch Test Accuracy: 48.666667\n",
      "Epoch Train Loss: 1.224433  Epoch Train Accuracy: 49.484127  Epoch Test Loss: 1.221608  Epoch Test Accuracy: 48.888889\n",
      "Epoch Train Loss: 1.179323  Epoch Train Accuracy: 49.285714  Epoch Test Loss: 1.177560  Epoch Test Accuracy: 48.888889\n",
      "Epoch Train Loss: 1.152901  Epoch Train Accuracy: 50.595238  Epoch Test Loss: 1.151868  Epoch Test Accuracy: 51.333333\n",
      "Epoch Train Loss: 1.139217  Epoch Train Accuracy: 50.595238  Epoch Test Loss: 1.138708  Epoch Test Accuracy: 51.111111\n",
      "Epoch Train Loss: 1.132996  Epoch Train Accuracy: 50.515873  Epoch Test Loss: 1.132682  Epoch Test Accuracy: 51.555556\n",
      "Epoch Train Loss: 1.130359  Epoch Train Accuracy: 50.595238  Epoch Test Loss: 1.130210  Epoch Test Accuracy: 51.111111\n",
      "Epoch Train Loss: 1.129257  Epoch Train Accuracy: 50.436508  Epoch Test Loss: 1.129083  Epoch Test Accuracy: 51.444444\n",
      "Epoch Train Loss: 1.128724  Epoch Train Accuracy: 50.476190  Epoch Test Loss: 1.128564  Epoch Test Accuracy: 51.444444\n",
      "Epoch Train Loss: 1.128409  Epoch Train Accuracy: 50.555556  Epoch Test Loss: 1.128304  Epoch Test Accuracy: 51.222222\n",
      "Fold 5\n",
      "Epoch Train Loss: 1.293740  Epoch Train Accuracy: 49.388889  Epoch Test Loss: 1.289989  Epoch Test Accuracy: 45.454545\n"
     ]
    }
   ],
   "source": [
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "num_attempts = 20\n",
    "\n",
    "random.seed(4815162352)\n",
    "batch_sizes = [int(np.round(2 ** random.uniform(4,5))) for i in range(num_attempts)]\n",
    "dropouts = [random.uniform(0,0.9) for i in range(num_attempts)]\n",
    "weight_decays = [np.exp(random.normalvariate(0,0.5)) for i in range(num_attempts)]\n",
    "stats = []\n",
    "fbs,fwd,fd = 0,0,0\n",
    "best_acc = -999\n",
    "\n",
    "disable = True\n",
    "epochs = 100\n",
    "every_other = 10\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "    batch_size = batch_sizes[i]\n",
    "    weight_decay = weight_decays[i]\n",
    "    dropout = dropouts[i]\n",
    "    print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "    for i in range(5):\n",
    "        torch.manual_seed(4815162342)\n",
    "        model = VGG19(dropout=dropout).cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        dlosscurve = []\n",
    "        dacccurve = []\n",
    "        vlosscurve = []\n",
    "        vacccurve = []\n",
    "        print(\"Fold %d\" % (i + 1))\n",
    "        my_data.setTest(i)\n",
    "        my_test.setTest(i)\n",
    "\n",
    "        my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        for j in range(epochs):\n",
    "            dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "            vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "            dlosscurve.append(dloss)\n",
    "            dacccurve.append(dacc)\n",
    "            vlosscurve.append(vloss)\n",
    "            vacccurve.append(vacc)\n",
    "            if j % every_other == every_other - 1:\n",
    "                print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "        df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "        df.plot.line()\n",
    "        avedloss += dloss\n",
    "        avedacc += dacc\n",
    "        avevloss += vloss\n",
    "        avevacc += vacc\n",
    "    avedloss /= 5\n",
    "    avedacc /= 0.05\n",
    "    avevloss /= 5\n",
    "    avevacc /= 0.05\n",
    "    if avevacc > best_acc:\n",
    "        fbs,fwd,fd,best_acc = batch_size, weight_decay, dropout, avevacc\n",
    "    print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "    print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\\nAverage Test Loss: {:.6f}\\nAverage Test Accuracy: {:.6f}\\n\".format(avedloss,avedacc,avevloss,avevacc))\n",
    "    stats.append([avedloss,avedacc,avevloss,avevacc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stats)):\n",
    "    print(\"{:.2f} & {:.2f} & {:.2f} & {} \\\\\\\\ \\\\hline\".format(batch_sizes[i],weight_decays[i],dropouts[i],\" & \".join([\"{:.2f}{}\".format(stats[i][j],\"\\\\%\" if j % 2 == 1 else \"\") for j in range(len(stats[i]))])))\n",
    "# hyperparameters\n",
    "batch_size = fbs\n",
    "weight_decay = fwd\n",
    "dropout = fd\n",
    "disable = False\n",
    "epochs = 100\n",
    "every_other = 10\n",
    "\n",
    "# initializing training objects\n",
    "torch.manual_seed(4815162342)\n",
    "model = VGG16(dropout=dropout).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# initializing dataset\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_val = AutoUXDataset(dataVal,labelsVal,False,True)\n",
    "my_loader = DataLoader(my_data, batch_size=batch_size,shuffle=True)\n",
    "my_val_loader = DataLoader(my_val, batch_size=batch_size,shuffle=True)\n",
    "my_data.setTest(-1)\n",
    "my_val.setTest(-1)\n",
    "\n",
    "# initializing tracking variables\n",
    "dlosscurve = []\n",
    "dacccurve = []\n",
    "vlosscurve = []\n",
    "vacccurve = []\n",
    "\n",
    "# training loop\n",
    "for j in range(epochs):\n",
    "    dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "    vloss, vacc = test(model,criterion,my_val_loader,disable)\n",
    "    dlosscurve.append(dloss)\n",
    "    dacccurve.append(dacc)\n",
    "    vlosscurve.append(vloss)\n",
    "    vacccurve.append(vacc)\n",
    "    if j % every_other == every_other - 1:\n",
    "        print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "\n",
    "print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "print(\"Train Loss: {:.6f}\\nTrain Accuracy: {:.6f}\\nValidation Loss: {:.6f}\\nValidation Accuracy: {:.6f}\\n\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "print(\"{} & {:.2f} & N/A & {:.2f} & {:.2f} & {:.2f}\\% & {:.2f} & {:.2f}\\% \\\\\\\\ \\\\hline\".format(batch_size,weight_decay,dropout,dloss,dacc * 100,vloss, vacc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.array([])\n",
    "preds = np.array([])\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(my_val,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model(x).cpu()\n",
    "        answers = np.append(answers,y_pred[:,1])\n",
    "        preds = np.append(preds,torch.max(y_pred,1)[1])\n",
    "answers = np.exp(answers)\n",
    "print(answers)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('VGG19outprobs.pt', 'wb') as f:\n",
    "    pickle.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "import pickle\n",
    "with open('VGG19out.pt', 'rb') as f:\n",
    "    y_pred = pickle.load(f)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "for x in labels:\n",
    "    y_test = np.append(y_test,x)\n",
    "\n",
    "class_names = [\"bad site\",\"good site\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "print(\"Accuracy: {:.4f}\".format(np.mean(y_test==y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
