{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataconv.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labels.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffonsoNet(nn.Module):\n",
    "\n",
    "    def __init__(self,dropout = 0.5):\n",
    "        super(AffonsoNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, kernel_size=10)\n",
    "        self.conv2 = nn.Conv2d(20, 25, kernel_size=10)\n",
    "        self.fc1 = nn.Linear(14875,4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 4)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv1(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv2(x)))\n",
    "        x = self.mp(x)\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = d + data[i];\n",
    "                l = l + labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc\n",
    "\n",
    "def test_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "batch_size = 128\n",
    "disable = False\n",
    "epochs = 50\n",
    "dropout = 0.5\n",
    "weight_decay = 0.5\n",
    "\n",
    "for i in range(5):\n",
    "    model = AffonsoNet(dropout=dropout).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "    #amp_handle.wrap_optimizer(optimizer)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #amp_handle = amp.init()\n",
    "    dlosscurve = []\n",
    "    dacccurve = []\n",
    "    vlosscurve = []\n",
    "    vacccurve = []\n",
    "    print(\"Fold %d\" % (i + 1))\n",
    "    my_data.setTest(i)\n",
    "    my_test.setTest(i)\n",
    "    \n",
    "    my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    for j in range(epochs):\n",
    "        dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "        vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "        dlosscurve.append(dloss)\n",
    "        dacccurve.append(dacc)\n",
    "        vlosscurve.append(vloss)\n",
    "        vacccurve.append(vacc)\n",
    "        if j % 1 == 0:\n",
    "            print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "    df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "    df.plot.line()\n",
    "    avedloss += dloss\n",
    "    avedacc += dacc\n",
    "    avevloss += vloss\n",
    "    avevacc += vacc\n",
    "avedloss /= 5\n",
    "avedacc /= 5\n",
    "avevloss /= 5\n",
    "avevacc /= 5\n",
    "print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\\nAverage Test Loss: {:.6f}\\nAverage Test Accuracy: {:.6f}\\n\".format(avedloss,avedacc,avevloss,avevacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXFullDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        super(AutoUXFullDataset,self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            d = d + data[i];\n",
    "            l = l + labels[i]\n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trainX)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:04<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 1.163997  Epoch Train Accuracy: 48.333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.738719  Epoch Train Accuracy: 50.997024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.696240  Epoch Train Accuracy: 53.080357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.683132  Epoch Train Accuracy: 56.780754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.716521  Epoch Train Accuracy: 56.840278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.660571  Epoch Train Accuracy: 60.783730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.635345  Epoch Train Accuracy: 64.131944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.648871  Epoch Train Accuracy: 63.551587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.635907  Epoch Train Accuracy: 65.694444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.623970  Epoch Train Accuracy: 66.309524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.622401  Epoch Train Accuracy: 65.749008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.628948  Epoch Train Accuracy: 64.503968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.627542  Epoch Train Accuracy: 65.634921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.624169  Epoch Train Accuracy: 67.212302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.603675  Epoch Train Accuracy: 67.564484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.616636  Epoch Train Accuracy: 65.853175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.639109  Epoch Train Accuracy: 64.216270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.608230  Epoch Train Accuracy: 65.223214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.605472  Epoch Train Accuracy: 68.918651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.598379  Epoch Train Accuracy: 68.040675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.611824  Epoch Train Accuracy: 67.311508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.592250  Epoch Train Accuracy: 68.516865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.579804  Epoch Train Accuracy: 70.545635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.594841  Epoch Train Accuracy: 69.697421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.561700  Epoch Train Accuracy: 73.839286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.577295  Epoch Train Accuracy: 69.563492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.579578  Epoch Train Accuracy: 69.335317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.567405  Epoch Train Accuracy: 69.181548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.550795  Epoch Train Accuracy: 70.897817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.583761  Epoch Train Accuracy: 70.277778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.539522  Epoch Train Accuracy: 71.532738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.535391  Epoch Train Accuracy: 72.668651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.528750  Epoch Train Accuracy: 74.722222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.519231  Epoch Train Accuracy: 75.069444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.514973  Epoch Train Accuracy: 74.136905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.510761  Epoch Train Accuracy: 74.717262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.504256  Epoch Train Accuracy: 74.424603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.509079  Epoch Train Accuracy: 75.089286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.506434  Epoch Train Accuracy: 75.496032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.506275  Epoch Train Accuracy: 75.342262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.459352  Epoch Train Accuracy: 79.246032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.476945  Epoch Train Accuracy: 77.574405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.466872  Epoch Train Accuracy: 77.534722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.456883  Epoch Train Accuracy: 79.047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.471258  Epoch Train Accuracy: 79.255952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.437397  Epoch Train Accuracy: 78.576389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.454762  Epoch Train Accuracy: 78.417659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.461504  Epoch Train Accuracy: 78.363095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.445803  Epoch Train Accuracy: 79.454365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.439925  Epoch Train Accuracy: 79.811508\n",
      "Average Train Loss: 0.439925\n",
      "Average Train Accuracy: 0.798115\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avedloss, avedacc = 0,0\n",
    "my_data = AutoUXFullDataset(data,labels)\n",
    "\n",
    "batch_size = 64\n",
    "disable = False\n",
    "epochs = 50\n",
    "every_other = 1\n",
    "\n",
    "model = AffonsoNet(0.5).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=0.1)\n",
    "#amp_handle.wrap_optimizer(optimizer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#amp_handle = amp.init()\n",
    "dlosscurve = []\n",
    "dacccurve = []\n",
    "\n",
    "my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "for j in range(epochs):\n",
    "    dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "    dlosscurve.append(dloss)\n",
    "    dacccurve.append(dacc)\n",
    "    if j % every_other == 0:\n",
    "        print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}\".format(dloss,dacc * 100))\n",
    "df = pd.DataFrame(data={\"train_loss\": dlosscurve})\n",
    "df.plot.line()\n",
    "avedloss += dloss\n",
    "avedacc += dacc\n",
    "print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\".format(avedloss,avedacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.60320154e-01 8.09366637e-01 8.91759168e-01 3.68900828e-01\n",
      " 9.62173138e-01 3.56582149e-01 7.97440795e-01 8.88447523e-01\n",
      " 6.77808159e-01 5.30904318e-01 6.18149181e-01 9.57050102e-01\n",
      " 9.23402576e-01 8.17705967e-01 7.95400141e-01 1.49685740e-01\n",
      " 3.85959794e-01 7.91364294e-01 2.17776072e-01 1.38559070e-01\n",
      " 5.79960070e-02 8.03906006e-01 2.14680735e-01 2.74122085e-01\n",
      " 6.87933538e-02 8.08756290e-02 1.45913361e-02 4.05803778e-02\n",
      " 1.28267511e-01 4.58231940e-02 7.19269766e-01 3.70082868e-01\n",
      " 2.90230011e-01 5.09318651e-01 8.19561128e-01 6.91764451e-01\n",
      " 5.96451843e-01 5.59982047e-01 7.60997708e-01 9.01559584e-02\n",
      " 7.64012052e-01 2.03472949e-01 4.29454841e-01 9.51248747e-01\n",
      " 8.65049121e-01 3.10848707e-02 6.97638952e-02 1.11163598e-01\n",
      " 8.27841438e-02 5.83365606e-02 1.10232759e-03 1.43823547e-01\n",
      " 3.23343285e-01 3.41526215e-02 2.62582003e-02 2.96616384e-02\n",
      " 2.83370191e-02 2.34646621e-02 2.00545564e-02 1.34699707e-02\n",
      " 4.93995415e-01 8.70190529e-01 8.47902631e-01 7.89770834e-01\n",
      " 2.14297097e-01 9.67442148e-01 9.23593251e-01 7.73503404e-01\n",
      " 3.12954450e-01 1.12168138e-01 9.24524733e-01 8.77388626e-01\n",
      " 6.68451616e-01 6.52948270e-01 4.35084786e-01 1.08205542e-01\n",
      " 2.25011696e-01 7.38176936e-02 2.11976365e-01 1.56952673e-02\n",
      " 3.58517314e-02 4.95668904e-02 3.19863560e-01 3.11918509e-01\n",
      " 4.91162051e-02 1.17363265e-01 1.48789776e-01 2.48353147e-01\n",
      " 3.04200929e-02 4.76288992e-02 1.29346315e-01 5.31230212e-02\n",
      " 1.05943768e-01 7.09067299e-01 9.64597274e-01 8.06616700e-01\n",
      " 8.87988199e-01 7.72423103e-01 8.62454349e-01 2.47772601e-01\n",
      " 8.01781325e-01 6.29047554e-01 5.21821488e-01 8.58037355e-01\n",
      " 8.66021488e-01 7.09437964e-01 8.87372540e-01 3.53212754e-01\n",
      " 9.47783291e-01 3.49900557e-01 1.22213068e-02 9.95367767e-02\n",
      " 2.57956699e-01 2.09168849e-01 5.35551562e-02 2.66927644e-01\n",
      " 2.18068848e-01 3.57357303e-02 6.20668850e-02 6.52672762e-02\n",
      " 6.98185727e-02 4.20987192e-02 3.51204281e-02 6.32304882e-02\n",
      " 7.72357361e-01 5.15707902e-01 6.71530247e-01 9.51788220e-01\n",
      " 5.79593919e-01 3.32448500e-01 7.13655350e-01 7.70024284e-01\n",
      " 1.87059365e-01 7.32288718e-01 4.27972545e-01 1.82534095e-01\n",
      " 4.95889486e-01 1.88984888e-01 5.99519820e-01 7.88540714e-01\n",
      " 9.03909478e-01 7.91887099e-01 4.13492950e-01 4.31146473e-01\n",
      " 3.90907871e-01 5.37362660e-01 4.42350551e-01 3.58432884e-01\n",
      " 3.86467480e-01 5.27323736e-01 5.20347055e-01 1.97467235e-01\n",
      " 1.05322885e-01 5.72861777e-02 3.48621349e-02 1.28848247e-01\n",
      " 4.92077428e-01 3.65430802e-01 8.07530124e-01 7.10689373e-01\n",
      " 5.39571316e-01 1.99180516e-01 9.80553977e-01 8.79666263e-01\n",
      " 6.78399072e-01 9.42065961e-01 2.50330964e-01 4.83378843e-01\n",
      " 2.94648620e-01 9.77657959e-01 3.07603949e-01 9.05645126e-01\n",
      " 2.54693632e-01 2.25495870e-01 7.00846516e-01 6.46326019e-02\n",
      " 2.77631748e-01 2.48405539e-03 6.28430084e-02 7.74205222e-02\n",
      " 1.63937253e-01 8.01194081e-02 2.61250205e-01 7.64273853e-01\n",
      " 8.21892612e-01 9.46871267e-01 7.75633958e-01 9.65159504e-01\n",
      " 7.49447502e-01 5.89560315e-01 3.98960311e-01 8.11176575e-01\n",
      " 7.52078738e-01 3.97634745e-01 6.69115408e-01 8.50462951e-01\n",
      " 8.21858713e-01 7.04555273e-01 9.01875643e-01 1.08854681e-01\n",
      " 2.89938970e-02 5.12419427e-02 2.13890882e-02 1.51340616e-02\n",
      " 7.29642992e-03 1.03803935e-01 1.53283754e-02 9.41955206e-02\n",
      " 2.83070085e-01 3.70953608e-02 2.17418649e-01 2.20702561e-01\n",
      " 6.98081219e-01 2.26162782e-01 8.25460435e-01 8.74029900e-01\n",
      " 7.99426264e-01 9.58742856e-01 8.35816188e-01 9.39045370e-01\n",
      " 9.30319245e-01 5.68267977e-01 7.25438399e-01 3.47784290e-01\n",
      " 9.16118087e-01 7.29331195e-01 9.22893274e-01 9.24448249e-01\n",
      " 2.69670289e-01 1.13251830e-01 1.98702480e-01 1.20537120e-01\n",
      " 1.25766711e-01 1.45312764e-01 2.44190175e-02 5.48913479e-02\n",
      " 1.37951762e-02 4.23904202e-02 2.15080232e-02 4.14355759e-02\n",
      " 8.94135688e-02 4.39998728e-02 7.73778394e-02 3.51423899e-02\n",
      " 8.67643839e-01 2.36489353e-01 5.17141201e-01 6.38512440e-01\n",
      " 4.26797577e-01 7.57487964e-01 4.57826594e-01 3.40007715e-01\n",
      " 1.14493548e-01 9.30905439e-01 9.05180149e-01 5.82168775e-01\n",
      " 4.94832226e-01 5.03626620e-01 4.78781477e-01 7.56247542e-01\n",
      " 6.60546266e-01 2.33346383e-01 1.43914565e-01 1.19382407e-01\n",
      " 1.74825814e-01 4.44753898e-01 4.12407877e-01 2.67870197e-01\n",
      " 1.36368702e-01 1.06604980e-01 1.19247342e-01 1.00908468e-01\n",
      " 2.11783689e-02 1.36275938e-02 1.63039129e-01 3.66671392e-01\n",
      " 8.57896416e-01 4.81404622e-01 6.69798863e-01 1.56660696e-01\n",
      " 2.96992184e-01 5.63404515e-01 7.33733137e-01 1.94869842e-01\n",
      " 2.35530752e-01 4.25208917e-01 3.12528879e-01 3.41830203e-01\n",
      " 7.10325505e-01 4.52298929e-01 2.09067090e-01 2.23599970e-01\n",
      " 5.33221424e-01 6.07491329e-01 9.46313343e-02 1.40295613e-01\n",
      " 9.67343862e-02 1.65773782e-01 2.05264714e-01 1.52104458e-01\n",
      " 5.71109144e-01 7.78738372e-02 7.90083254e-02 3.75058527e-01\n",
      " 3.67093529e-01 8.76844674e-02 3.49634081e-01 1.05635854e-01\n",
      " 1.38837736e-01 8.32284165e-01 6.62044399e-01 9.97805622e-01\n",
      " 7.99397865e-01 5.11957115e-01 6.25569648e-01 8.50949323e-01\n",
      " 8.83007700e-01 6.62366321e-01 8.12756058e-01 5.19085651e-01\n",
      " 9.64876047e-01 5.49113701e-01 8.89977561e-01 4.16127001e-01\n",
      " 2.14806883e-02 4.85894555e-02 2.00385268e-01 1.83193685e-02\n",
      " 1.94720226e-01 2.77079888e-01 5.85132592e-01 1.53702523e-01\n",
      " 1.41002931e-01 3.85002295e-03 1.68978602e-01 3.84135119e-02\n",
      " 2.38226334e-01 3.56761663e-01 2.66116063e-01 3.97696656e-01\n",
      " 2.89379938e-01 4.27667667e-01 9.03288595e-01 9.22797344e-01\n",
      " 1.27963770e-01 2.51572106e-01 7.89879489e-01 5.85249510e-01\n",
      " 4.18645409e-01 9.54834319e-01 3.24361252e-01 9.68967987e-01\n",
      " 3.66708766e-01 4.82482366e-01 1.75275366e-01 1.95572101e-01\n",
      " 1.30229418e-01 3.21633164e-01 2.47004391e-01 8.17404425e-01\n",
      " 3.91878631e-01 1.64478465e-01 4.08608873e-01 3.14676377e-01\n",
      " 3.52535662e-01 5.79726316e-01 6.32217623e-01 6.14470849e-01\n",
      " 8.96729378e-01 9.18061240e-01 9.54456039e-01 4.77508569e-01\n",
      " 7.32108213e-01 9.28567746e-01 7.16142825e-01 6.42223363e-01\n",
      " 9.36833748e-01 9.49446979e-01 4.33521762e-01 6.18342572e-01\n",
      " 9.41736297e-01 3.24376488e-01 2.77010202e-01 3.95636914e-01\n",
      " 2.97984625e-01 9.23377229e-02 1.32160852e-01 4.05712552e-02\n",
      " 3.25759591e-01 2.22907370e-01 9.44671363e-02 2.83691962e-02\n",
      " 2.85186547e-02 2.62046664e-01 1.48990270e-01 2.24084232e-01\n",
      " 5.45166936e-01 6.59314297e-01 8.77437367e-01 7.45526074e-01\n",
      " 8.81942873e-01 6.86483220e-01 1.40552536e-01 9.47106981e-01\n",
      " 8.72569093e-01 6.83136327e-01 6.69685331e-01 4.47927419e-01\n",
      " 5.76827426e-01 7.19407827e-01 8.14159044e-01 5.48576215e-01\n",
      " 1.55123255e-01 2.02062144e-01 4.91290896e-01 6.17023775e-02\n",
      " 1.03266698e-01 8.33177164e-02 1.11470081e-01 4.25396457e-01\n",
      " 2.41533312e-01 9.32214473e-02 3.65914668e-01 1.59690118e-01\n",
      " 1.37624338e-01 3.65150278e-01 6.01311201e-01 2.10093095e-02\n",
      " 3.06107024e-01 5.09824298e-01 8.37760172e-01 7.25446701e-01\n",
      " 6.83136490e-01 7.02993793e-01 7.64712576e-01 6.02662056e-01\n",
      " 7.75930450e-01 8.50356505e-01 9.68401692e-01 8.87320919e-01\n",
      " 6.26474732e-01 7.55954966e-01 4.85404325e-01 5.58867347e-01\n",
      " 9.06937668e-02 3.69719432e-01 1.79547722e-01 7.92421207e-01\n",
      " 6.11564931e-01 4.07356563e-01 7.11929048e-02 3.38920725e-01\n",
      " 1.53328863e-01 3.14175049e-01 2.39653571e-01 4.12564048e-01\n",
      " 4.60134128e-01 1.95910821e-01 1.74114092e-01 7.88574154e-02\n",
      " 5.31391105e-01 9.41821621e-01 5.48630757e-01 8.49168666e-01\n",
      " 6.83606702e-01 7.32278766e-01 6.15363543e-01 8.36094620e-01\n",
      " 1.59252802e-01 4.89571356e-01 7.57017829e-01 2.84327527e-01\n",
      " 3.94681074e-01 7.95287124e-01 5.39570913e-02 3.27295807e-01\n",
      " 1.90991378e-01 1.52325106e-01 3.94317535e-02 2.05311896e-01\n",
      " 3.33287951e-01 3.30045407e-01 1.59957291e-01 4.29033202e-01\n",
      " 9.58415323e-02 6.25052897e-02 2.59472817e-01 2.91762519e-01\n",
      " 4.85437178e-02 2.45276142e-01 7.79490520e-01 2.34886471e-01\n",
      " 9.88383109e-01 4.56465828e-01 4.14526467e-01 8.28142710e-01\n",
      " 4.32044175e-01 8.23860387e-01 9.14688338e-01 8.00885860e-01\n",
      " 5.24518594e-01 7.90864084e-01 6.96632240e-01 9.56951990e-01\n",
      " 6.21352762e-01 3.70399931e-02 1.81714677e-02 4.53617801e-01\n",
      " 6.31209254e-02 5.68250598e-03 1.37273920e-02 6.69527398e-03\n",
      " 8.68890376e-04 6.27589484e-03 2.25813911e-01 3.67504850e-01\n",
      " 4.08423573e-01 2.13462592e-02 4.89897923e-02 5.62224855e-03\n",
      " 2.33262501e-01 5.25323753e-01 3.96651192e-01 3.72866754e-02\n",
      " 6.13400419e-01 8.58772902e-01 9.50345623e-01 6.28590742e-01\n",
      " 8.83884131e-01 9.29451060e-01 9.77200740e-01 8.77395947e-01\n",
      " 9.50281277e-01 2.89725042e-01 8.72348602e-01 5.96480000e-01\n",
      " 8.48257691e-01 7.81435581e-01 5.88415706e-01 9.65249712e-01\n",
      " 4.04020052e-01 4.02066293e-01 1.63458470e-01 1.44985372e-01\n",
      " 2.28283362e-01 6.75242402e-02 1.08110285e-01 3.58373880e-01\n",
      " 1.41338128e-01 2.28147253e-01 9.06605166e-02 6.58151761e-02\n",
      " 4.87407209e-01 4.65356571e-01 2.52193149e-01 1.58956143e-01\n",
      " 2.26638221e-01 2.76884284e-01 4.58415205e-01 8.16205013e-01\n",
      " 9.31044609e-01 9.51967052e-01 9.35870674e-01 8.85505743e-01\n",
      " 5.90011270e-01 9.74453547e-01 9.33996485e-01 8.62032304e-01\n",
      " 9.20475623e-01 9.36708675e-01 6.95740077e-01 9.88433068e-01\n",
      " 2.13438680e-01 3.23442737e-02 1.41340747e-03 1.31350055e-01\n",
      " 8.89775949e-03 6.35758630e-05 6.83311676e-05 4.38098767e-07\n",
      " 1.67536355e-04 5.04275072e-05 4.36917616e-03 3.12211475e-04\n",
      " 8.89754793e-01 8.57334324e-01 3.84919027e-01 8.05263572e-01\n",
      " 2.68357452e-01 5.47319841e-01 9.69050234e-01 2.97244014e-01\n",
      " 9.60461961e-01 7.34814510e-01 7.21000609e-01 8.60125504e-01\n",
      " 6.94659894e-01 3.67303511e-01 7.14383106e-01 5.35876637e-01\n",
      " 4.09671630e-02 3.16992582e-01 7.28190328e-02 1.41394207e-02\n",
      " 1.58689692e-02 2.87137608e-02 8.46963074e-03 2.08338778e-04\n",
      " 1.03894666e-05 1.06560341e-06 5.81276245e-03 1.39117211e-01\n",
      " 1.60657997e-02 2.11449638e-02 2.58867482e-01 7.03340824e-01\n",
      " 8.21016184e-01 5.38368295e-01 5.35352171e-01 4.34559699e-01\n",
      " 8.96028184e-01 5.99380045e-01 9.11817702e-01 8.27667400e-01\n",
      " 8.74758717e-01 7.15232667e-01 9.91415840e-01 8.48839129e-01\n",
      " 4.73562522e-01 1.03869512e-02 1.28888738e-02 2.66806555e-02\n",
      " 1.20739719e-02 7.43620018e-02 1.13234718e-07 5.11672867e-04\n",
      " 7.90602762e-02 1.63570570e-05 3.75853739e-01 1.70046624e-01\n",
      " 2.34920011e-02 3.01079069e-05 1.21276661e-01 2.28508630e-02\n",
      " 6.02193535e-01 7.00735073e-01 1.84887374e-01 7.66869195e-01\n",
      " 2.66951414e-01 3.71220369e-01 3.60048533e-01 9.64058356e-01\n",
      " 2.13362973e-01 4.57642815e-01 2.31171579e-01 2.33870348e-01\n",
      " 5.82580184e-01 7.76546362e-01 3.94434141e-01 3.32758400e-01\n",
      " 2.38421429e-01 8.68603563e-02 1.65224309e-01 2.22233870e-01\n",
      " 3.02560245e-01 1.05392365e-01 2.47776146e-01 1.01704752e-01\n",
      " 1.63440934e-01 2.63035095e-01 6.03927655e-02 2.60616365e-01\n",
      " 2.96175718e-01 2.35459839e-01 2.77939317e-01 2.33710876e-01\n",
      " 3.56690561e-01 6.68751939e-01 1.73076820e-01 3.86824783e-01\n",
      " 4.49364982e-01 2.80110173e-01 7.99025346e-01 7.09955731e-01\n",
      " 7.95515259e-01 5.52982105e-01 5.53330275e-01 1.15559144e-01\n",
      " 5.16382316e-01 6.44794601e-01 7.65208834e-01 9.03001350e-01\n",
      " 2.20985099e-01 1.29228873e-01 1.44298891e-01 2.04865052e-01\n",
      " 8.31239256e-02 1.36364801e-01 3.35654188e-01 1.84386779e-03\n",
      " 1.94031827e-01 9.28471196e-02 1.83454408e-01 4.20857432e-02\n",
      " 9.99750613e-02 4.39580780e-02 1.08104431e-02 7.62106908e-01\n",
      " 1.10569156e-01 2.14752763e-01 1.04602117e-01 3.69571637e-01\n",
      " 7.33989112e-01 8.14780241e-01 5.57331555e-01 3.22383195e-01\n",
      " 5.20774742e-01 7.59829613e-01 8.21084893e-01 7.06797996e-01\n",
      " 5.48619116e-01 2.51750789e-01 7.62032233e-01 4.03418175e-01\n",
      " 9.73943489e-01 6.28651816e-01 4.76561052e-01 2.74775604e-01\n",
      " 2.67860513e-02 2.05249396e-01 4.04097588e-02 8.62192806e-02\n",
      " 7.97148222e-02 4.02703967e-02 3.39472344e-01 1.88490040e-01\n",
      " 2.81195154e-02 1.46108445e-02 2.68779485e-01 1.30941419e-01\n",
      " 8.56512781e-02 1.39978802e-02 2.49712870e-01 1.51575622e-02\n",
      " 3.51524426e-01 3.86168598e-01 6.98050762e-01 3.96331441e-01\n",
      " 9.69164374e-01 6.21375872e-01 6.47297091e-02 6.50905436e-01\n",
      " 9.65568269e-01 3.30813714e-01 8.32887220e-01 9.56360338e-01\n",
      " 8.80919235e-01 5.38570367e-01 3.29389439e-01 6.33153609e-01\n",
      " 9.65030189e-01 3.38207483e-01 2.44692638e-01 2.93376902e-01\n",
      " 4.92576821e-01 5.10989833e-02 2.95457319e-01 2.83236495e-01\n",
      " 6.24946969e-01 2.11214294e-01 4.33568173e-01 3.85441564e-01\n",
      " 4.04038450e-01 2.09915082e-01 5.23067030e-01 3.16694269e-01\n",
      " 7.40259449e-01 9.20125872e-01 7.78688640e-01 5.03563285e-01\n",
      " 3.26515897e-01 4.74565059e-01 2.94934078e-01 3.64510654e-01\n",
      " 2.24377384e-01 9.10357548e-01 8.63417623e-01 4.87751651e-01\n",
      " 8.13464424e-01 3.72400253e-01 6.84666923e-01 3.32796007e-01\n",
      " 6.37892999e-01 2.61224949e-01 1.23810026e-02 9.56964280e-02\n",
      " 7.78079167e-02 4.08675793e-02 9.38598347e-02 7.71698564e-02\n",
      " 5.91642175e-02 1.27896912e-01 1.00011346e-01 9.88442462e-02\n",
      " 9.41575070e-02 6.30090435e-02 7.96667148e-02 1.87106266e-01\n",
      " 2.06832359e-01 2.59307881e-01 8.08604000e-01 4.61039531e-01\n",
      " 8.39067074e-01 9.48357879e-01 9.52896708e-01 6.30146041e-01\n",
      " 4.11161520e-01 6.95995244e-01 9.08838842e-01 6.22394480e-01\n",
      " 7.64198419e-01 4.34256340e-01 9.44651573e-01 6.68397432e-01\n",
      " 7.85950139e-02 1.25275109e-01 4.40436591e-03 5.19686464e-02\n",
      " 1.88884955e-01 9.85498678e-03 3.23784691e-02 6.15274474e-02\n",
      " 2.40513112e-02 8.41253027e-02 1.14366168e-01 4.81031844e-02\n",
      " 4.83351300e-01 4.25148348e-01 3.33775648e-01 5.50322429e-01\n",
      " 8.68437312e-01 1.47652812e-01 5.89970196e-01 6.80854720e-01\n",
      " 7.84765285e-01 2.91120824e-01 7.56862266e-01 7.88482435e-01\n",
      " 7.95102844e-01 5.40334456e-01 7.86857257e-01 7.10020055e-01\n",
      " 7.21838764e-01 7.50979837e-01 3.75609899e-01 7.80995085e-01\n",
      " 2.97853789e-01 2.64217712e-01 3.60258994e-01 3.39740309e-01\n",
      " 2.82155199e-01 1.76988862e-01 2.84702172e-01 1.97955892e-01\n",
      " 3.23860208e-01 3.87451322e-01 2.68097526e-01 2.33348691e-01\n",
      " 1.55586934e-01 2.09647759e-03 3.42973868e-01 2.53905234e-01\n",
      " 2.43477193e-01 6.75151910e-03 5.82598519e-01 7.09819484e-01\n",
      " 8.53878900e-01 4.69982547e-01 8.86465385e-01 3.40675407e-01\n",
      " 9.30050899e-01 5.97994628e-01 9.63062244e-01 8.95851957e-01\n",
      " 8.40387436e-01 3.46926400e-01 9.17487508e-01 7.25933055e-01\n",
      " 7.84470467e-01 9.44194932e-01 1.31055226e-02 3.69468472e-01\n",
      " 6.83872048e-03 2.14834086e-01 5.14950060e-02 1.18917206e-01\n",
      " 8.82296803e-02 8.18097507e-02 7.93173472e-02 1.85169368e-02\n",
      " 3.12951232e-02 2.90407623e-01 9.96296541e-03 3.63591164e-02\n",
      " 6.11178131e-02 3.73201174e-01 3.01054595e-01 7.40121799e-01\n",
      " 9.02072841e-01 2.37153918e-01 2.89128565e-01 7.44037152e-01\n",
      " 6.43194558e-01 8.69976446e-01 8.44153677e-01 6.99303259e-01\n",
      " 3.31449244e-01 7.20336522e-01 7.40278511e-01 5.19852785e-01\n",
      " 3.26713183e-01 9.26395377e-01 2.21804051e-01 3.32545015e-01\n",
      " 4.09205567e-01 1.67491819e-01 4.32639917e-01 2.67802253e-01\n",
      " 3.13260032e-01 1.31959533e-01 1.57057603e-01 2.85028786e-01\n",
      " 1.08109125e-01 2.51964077e-01 1.56309955e-01 1.88600758e-01\n",
      " 2.63627359e-01 4.78826455e-01]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "answers = np.array([])\n",
    "preds = np.array([])\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(my_loader,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model(x).cpu()\n",
    "        answers = np.append(answers,y_pred[:,1])\n",
    "        preds = np.append(preds,torch.max(y_pred,1)[1])\n",
    "answers = np.exp(answers)\n",
    "print(answers)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AffonsoNetoutprobs.pt', 'wb') as f:\n",
    "    pickle.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "import pickle\n",
    "with open('AffonsoNetout.pt', 'rb') as f:\n",
    "    y_pred = pickle.load(f)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "for x in labels:\n",
    "    y_test = np.append(y_test,x)\n",
    "\n",
    "class_names = [\"bad site\",\"good site\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
