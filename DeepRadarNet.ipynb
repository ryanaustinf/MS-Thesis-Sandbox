{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataconvall.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labelsall.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "    \n",
    "with open('datavalconvall.pt', 'rb') as f:\n",
    "    dataVal = pickle.load(f)\n",
    "    \n",
    "with open('labelsval.pt', 'rb') as f:\n",
    "    labelsVal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRadarNet(nn.Module):\n",
    "\n",
    "    def __init__(self,dropout = 0.5):\n",
    "        super(DeepRadarNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11)\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(24576,4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv1(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv2(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(self.conv3(x))\n",
    "        x = self.dropout(self.conv4(x))\n",
    "        x = self.dropout(torch.relu(self.conv5(x)))\n",
    "        x = self.mp(x)\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True,isVal=False):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.isVal = isVal\n",
    "        if isVal:\n",
    "            self.testX = torch.from_numpy(np.asarray(data,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "            self.testY = torch.from_numpy(np.asarray(labels,dtype=np.uint8)).type('torch.LongTensor')\n",
    "        else:\n",
    "            self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        if self.isVal:\n",
    "            d = self.data\n",
    "            l = self.labels\n",
    "            self.testX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "            self.testY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "            return\n",
    "        d = np.empty((0,3,384,683),int)\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = np.append(d,self.data[i],axis=0)\n",
    "                l += self.labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc\n",
    "\n",
    "def test_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 48\n",
      "Weight Decay: 1.1101254708379769\n",
      "Dropout: 0.02630191277913222\n",
      "\n",
      "Fold 1\n",
      "Epoch Train Loss: 0.693108  Epoch Train Accuracy: 50.990338  Epoch Test Loss: 0.693062  Epoch Test Accuracy: 51.596102\n",
      "Epoch Train Loss: 0.693076  Epoch Train Accuracy: 51.002415  Epoch Test Loss: 0.693254  Epoch Test Accuracy: 49.025538\n",
      "Epoch Train Loss: 0.693059  Epoch Train Accuracy: 50.978261  Epoch Test Loss: 0.693206  Epoch Test Accuracy: 49.596774\n",
      "Epoch Train Loss: 0.693059  Epoch Train Accuracy: 50.972222  Epoch Test Loss: 0.693078  Epoch Test Accuracy: 50.739247\n",
      "Epoch Train Loss: 0.693065  Epoch Train Accuracy: 50.960145  Epoch Test Loss: 0.693144  Epoch Test Accuracy: 50.168011\n",
      "Epoch Train Loss: 0.693058  Epoch Train Accuracy: 50.996377  Epoch Test Loss: 0.693306  Epoch Test Accuracy: 48.739919\n",
      "Epoch Train Loss: 0.693050  Epoch Train Accuracy: 50.984300  Epoch Test Loss: 0.693346  Epoch Test Accuracy: 48.454301\n",
      "Fold 2\n",
      "Epoch Train Loss: 0.693154  Epoch Train Accuracy: 50.403747  Epoch Test Loss: 0.693126  Epoch Test Accuracy: 52.941176\n",
      "Epoch Train Loss: 0.693137  Epoch Train Accuracy: 50.387597  Epoch Test Loss: 0.693089  Epoch Test Accuracy: 51.439951\n",
      "Epoch Train Loss: 0.693138  Epoch Train Accuracy: 50.339147  Epoch Test Loss: 0.693057  Epoch Test Accuracy: 52.297794\n",
      "Epoch Train Loss: 0.693154  Epoch Train Accuracy: 50.355297  Epoch Test Loss: 0.692962  Epoch Test Accuracy: 54.013480\n",
      "Epoch Train Loss: 0.693160  Epoch Train Accuracy: 50.387597  Epoch Test Loss: 0.693061  Epoch Test Accuracy: 52.726716\n",
      "Epoch Train Loss: 0.693141  Epoch Train Accuracy: 50.274548  Epoch Test Loss: 0.693069  Epoch Test Accuracy: 51.868873\n",
      "Epoch Train Loss: 0.693146  Epoch Train Accuracy: 50.419897  Epoch Test Loss: 0.693092  Epoch Test Accuracy: 51.654412\n",
      "Fold 3\n",
      "Epoch Train Loss: 0.693097  Epoch Train Accuracy: 50.982906  Epoch Test Loss: 0.693117  Epoch Test Accuracy: 50.548246\n",
      "Epoch Train Loss: 0.693082  Epoch Train Accuracy: 51.047009  Epoch Test Loss: 0.693179  Epoch Test Accuracy: 49.725877\n",
      "Epoch Train Loss: 0.693081  Epoch Train Accuracy: 50.822650  Epoch Test Loss: 0.693164  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 0.693050  Epoch Train Accuracy: 51.047009  Epoch Test Loss: 0.693100  Epoch Test Accuracy: 50.548246\n",
      "Epoch Train Loss: 0.693072  Epoch Train Accuracy: 50.886752  Epoch Test Loss: 0.693117  Epoch Test Accuracy: 50.411184\n",
      "Epoch Train Loss: 0.693075  Epoch Train Accuracy: 50.854701  Epoch Test Loss: 0.693162  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 0.693068  Epoch Train Accuracy: 50.854701  Epoch Test Loss: 0.693182  Epoch Test Accuracy: 49.862939\n",
      "Fold 4\n",
      "Epoch Train Loss: 0.693156  Epoch Train Accuracy: 50.643939  Epoch Test Loss: 0.693113  Epoch Test Accuracy: 51.893939\n",
      "Epoch Train Loss: 0.693125  Epoch Train Accuracy: 50.580808  Epoch Test Loss: 0.693110  Epoch Test Accuracy: 50.710227\n",
      "Epoch Train Loss: 0.693119  Epoch Train Accuracy: 50.568182  Epoch Test Loss: 0.693074  Epoch Test Accuracy: 51.183712\n",
      "Epoch Train Loss: 0.693122  Epoch Train Accuracy: 50.618687  Epoch Test Loss: 0.693067  Epoch Test Accuracy: 51.420455\n",
      "Epoch Train Loss: 0.693127  Epoch Train Accuracy: 50.681818  Epoch Test Loss: 0.693082  Epoch Test Accuracy: 51.183712\n",
      "Epoch Train Loss: 0.693125  Epoch Train Accuracy: 50.555556  Epoch Test Loss: 0.692979  Epoch Test Accuracy: 52.840909\n",
      "Epoch Train Loss: 0.693123  Epoch Train Accuracy: 50.568182  Epoch Test Loss: 0.693107  Epoch Test Accuracy: 50.710227\n",
      "Fold 5\n",
      "Epoch Train Loss: 0.693108  Epoch Train Accuracy: 50.944444  Epoch Test Loss: 0.693126  Epoch Test Accuracy: 50.492680\n",
      "Epoch Train Loss: 0.693092  Epoch Train Accuracy: 50.833333  Epoch Test Loss: 0.693154  Epoch Test Accuracy: 50.028153\n",
      "Epoch Train Loss: 0.693076  Epoch Train Accuracy: 50.916667  Epoch Test Loss: 0.693127  Epoch Test Accuracy: 50.337838\n",
      "Epoch Train Loss: 0.693098  Epoch Train Accuracy: 50.666667  Epoch Test Loss: 0.693126  Epoch Test Accuracy: 50.337838\n",
      "Epoch Train Loss: 0.693070  Epoch Train Accuracy: 50.888889  Epoch Test Loss: 0.693108  Epoch Test Accuracy: 50.492680\n",
      "Epoch Train Loss: 0.693099  Epoch Train Accuracy: 50.694444  Epoch Test Loss: 0.693063  Epoch Test Accuracy: 50.957207\n",
      "Epoch Train Loss: 0.693074  Epoch Train Accuracy: 50.888889  Epoch Test Loss: 0.693174  Epoch Test Accuracy: 49.873311\n",
      "Batch Size: 48\n",
      "Weight Decay: 1.1101254708379769\n",
      "Dropout: 0.02630191277913222\n",
      "\n",
      "Average Train Loss: 0.693092\n",
      "Average Train Accuracy: 50.743194\n",
      "Average Test Loss: 0.693180\n",
      "Average Test Accuracy: 50.111038\n",
      "\n",
      "Batch Size: 37\n",
      "Weight Decay: 0.8002187631784285\n",
      "Dropout: 0.46909702534897096\n",
      "\n",
      "Fold 1\n",
      "Epoch Train Loss: 0.693090  Epoch Train Accuracy: 51.243243  Epoch Test Loss: 0.693113  Epoch Test Accuracy: 50.630631\n",
      "Epoch Train Loss: 0.693050  Epoch Train Accuracy: 51.243243  Epoch Test Loss: 0.693220  Epoch Test Accuracy: 49.429429\n",
      "Epoch Train Loss: 0.693040  Epoch Train Accuracy: 51.045045  Epoch Test Loss: 0.693214  Epoch Test Accuracy: 49.629630\n",
      "Epoch Train Loss: 0.693040  Epoch Train Accuracy: 51.045045  Epoch Test Loss: 0.693112  Epoch Test Accuracy: 50.430430\n",
      "Epoch Train Loss: 0.693094  Epoch Train Accuracy: 50.648649  Epoch Test Loss: 0.693141  Epoch Test Accuracy: 50.230230\n",
      "Epoch Train Loss: 0.693122  Epoch Train Accuracy: 50.450450  Epoch Test Loss: 0.693294  Epoch Test Accuracy: 49.229229\n",
      "Epoch Train Loss: 0.693029  Epoch Train Accuracy: 51.045045  Epoch Test Loss: 0.693309  Epoch Test Accuracy: 49.029029\n",
      "Fold 2\n",
      "Epoch Train Loss: 0.693152  Epoch Train Accuracy: 50.619369  Epoch Test Loss: 0.693122  Epoch Test Accuracy: 52.666667\n",
      "Epoch Train Loss: 0.693101  Epoch Train Accuracy: 50.900901  Epoch Test Loss: 0.693057  Epoch Test Accuracy: 51.783784\n",
      "Epoch Train Loss: 0.693140  Epoch Train Accuracy: 50.337838  Epoch Test Loss: 0.693062  Epoch Test Accuracy: 52.162162\n",
      "Epoch Train Loss: 0.693151  Epoch Train Accuracy: 50.337838  Epoch Test Loss: 0.693031  Epoch Test Accuracy: 53.171171\n",
      "Epoch Train Loss: 0.693143  Epoch Train Accuracy: 50.900901  Epoch Test Loss: 0.693046  Epoch Test Accuracy: 52.792793\n",
      "Epoch Train Loss: 0.693183  Epoch Train Accuracy: 49.493243  Epoch Test Loss: 0.693027  Epoch Test Accuracy: 52.162162\n",
      "Epoch Train Loss: 0.693133  Epoch Train Accuracy: 50.619369  Epoch Test Loss: 0.693075  Epoch Test Accuracy: 51.909910\n",
      "Fold 3\n",
      "Epoch Train Loss: 0.693059  Epoch Train Accuracy: 51.858108  Epoch Test Loss: 0.693138  Epoch Test Accuracy: 50.238474\n",
      "Epoch Train Loss: 0.693006  Epoch Train Accuracy: 52.347973  Epoch Test Loss: 0.693161  Epoch Test Accuracy: 49.904610\n",
      "Epoch Train Loss: 0.692977  Epoch Train Accuracy: 51.368243  Epoch Test Loss: 0.693184  Epoch Test Accuracy: 49.952305\n",
      "Epoch Train Loss: 0.692907  Epoch Train Accuracy: 51.858108  Epoch Test Loss: 0.693147  Epoch Test Accuracy: 50.190779\n",
      "Epoch Train Loss: 0.693042  Epoch Train Accuracy: 50.878378  Epoch Test Loss: 0.693166  Epoch Test Accuracy: 50.095390\n",
      "Epoch Train Loss: 0.693191  Epoch Train Accuracy: 49.898649  Epoch Test Loss: 0.693169  Epoch Test Accuracy: 50.000000\n",
      "Epoch Train Loss: 0.693182  Epoch Train Accuracy: 49.898649  Epoch Test Loss: 0.693180  Epoch Test Accuracy: 49.904610\n",
      "Fold 4\n",
      "Epoch Train Loss: 0.693139  Epoch Train Accuracy: 50.914761  Epoch Test Loss: 0.693083  Epoch Test Accuracy: 51.724138\n",
      "Epoch Train Loss: 0.693128  Epoch Train Accuracy: 50.415800  Epoch Test Loss: 0.693057  Epoch Test Accuracy: 51.127679\n",
      "Epoch Train Loss: 0.693091  Epoch Train Accuracy: 50.914761  Epoch Test Loss: 0.693048  Epoch Test Accuracy: 51.425909\n",
      "Epoch Train Loss: 0.693079  Epoch Train Accuracy: 51.413721  Epoch Test Loss: 0.693066  Epoch Test Accuracy: 51.425909\n",
      "Epoch Train Loss: 0.693084  Epoch Train Accuracy: 51.164241  Epoch Test Loss: 0.693029  Epoch Test Accuracy: 51.575023\n",
      "Epoch Train Loss: 0.693151  Epoch Train Accuracy: 50.166320  Epoch Test Loss: 0.693026  Epoch Test Accuracy: 52.320596\n",
      "Epoch Train Loss: 0.693113  Epoch Train Accuracy: 50.665281  Epoch Test Loss: 0.693066  Epoch Test Accuracy: 51.127679\n",
      "Fold 5\n",
      "Epoch Train Loss: 0.693083  Epoch Train Accuracy: 51.021021  Epoch Test Loss: 0.693119  Epoch Test Accuracy: 50.499590\n",
      "Epoch Train Loss: 0.693104  Epoch Train Accuracy: 50.600601  Epoch Test Loss: 0.693143  Epoch Test Accuracy: 50.171990\n",
      "Epoch Train Loss: 0.693006  Epoch Train Accuracy: 51.441441  Epoch Test Loss: 0.693129  Epoch Test Accuracy: 50.303030\n",
      "Epoch Train Loss: 0.693151  Epoch Train Accuracy: 50.180180  Epoch Test Loss: 0.693136  Epoch Test Accuracy: 50.237510\n",
      "Epoch Train Loss: 0.692998  Epoch Train Accuracy: 51.441441  Epoch Test Loss: 0.693121  Epoch Test Accuracy: 50.368550\n",
      "Epoch Train Loss: 0.693274  Epoch Train Accuracy: 49.339339  Epoch Test Loss: 0.693094  Epoch Test Accuracy: 50.565111\n",
      "Epoch Train Loss: 0.693031  Epoch Train Accuracy: 51.021021  Epoch Test Loss: 0.693168  Epoch Test Accuracy: 50.040950\n",
      "Batch Size: 37\n",
      "Weight Decay: 0.8002187631784285\n",
      "Dropout: 0.46909702534897096\n",
      "\n",
      "Average Train Loss: 0.693098\n",
      "Average Train Accuracy: 50.649873\n",
      "Average Test Loss: 0.693159\n",
      "Average Test Accuracy: 50.402436\n",
      "\n",
      "Batch Size: 97\n",
      "Weight Decay: 1.5891250179825203\n",
      "Dropout: 0.5068946035196518\n",
      "\n",
      "Fold 1\n",
      "Epoch Train Loss: 0.693066  Epoch Train Accuracy: 51.956119  Epoch Test Loss: 0.693150  Epoch Test Accuracy: 49.993391\n",
      "Epoch Train Loss: 0.693023  Epoch Train Accuracy: 51.764473  Epoch Test Loss: 0.693155  Epoch Test Accuracy: 49.993391\n",
      "Epoch Train Loss: 0.693076  Epoch Train Accuracy: 50.997885  Epoch Test Loss: 0.693216  Epoch Test Accuracy: 49.240021\n",
      "Epoch Train Loss: 0.693050  Epoch Train Accuracy: 51.189532  Epoch Test Loss: 0.693158  Epoch Test Accuracy: 49.993391\n",
      "Epoch Train Loss: 0.693085  Epoch Train Accuracy: 50.806238  Epoch Test Loss: 0.693160  Epoch Test Accuracy: 49.993391\n",
      "Epoch Train Loss: 0.692999  Epoch Train Accuracy: 51.572826  Epoch Test Loss: 0.693254  Epoch Test Accuracy: 49.114459\n",
      "Epoch Train Loss: 0.693048  Epoch Train Accuracy: 51.189532  Epoch Test Loss: 0.693194  Epoch Test Accuracy: 49.616706\n",
      "Fold 2\n",
      "Epoch Train Loss: 0.693159  Epoch Train Accuracy: 48.804410  Epoch Test Loss: 0.693160  Epoch Test Accuracy: 47.683594\n",
      "Epoch Train Loss: 0.693111  Epoch Train Accuracy: 50.977234  Epoch Test Loss: 0.693050  Epoch Test Accuracy: 52.418226\n",
      "Epoch Train Loss: 0.693137  Epoch Train Accuracy: 50.322165  Epoch Test Loss: 0.693069  Epoch Test Accuracy: 51.909126\n",
      "Epoch Train Loss: 0.693143  Epoch Train Accuracy: 50.322165  Epoch Test Loss: 0.693080  Epoch Test Accuracy: 52.825506\n",
      "Epoch Train Loss: 0.693134  Epoch Train Accuracy: 50.758877  Epoch Test Loss: 0.693090  Epoch Test Accuracy: 52.214586\n",
      "Epoch Train Loss: 0.693196  Epoch Train Accuracy: 48.793671  Epoch Test Loss: 0.693077  Epoch Test Accuracy: 52.010946\n",
      "Epoch Train Loss: 0.693139  Epoch Train Accuracy: 50.758877  Epoch Test Loss: 0.693107  Epoch Test Accuracy: 52.214586\n",
      "Fold 3\n",
      "Epoch Train Loss: 0.693130  Epoch Train Accuracy: 51.361147  Epoch Test Loss: 0.693143  Epoch Test Accuracy: 50.254700\n"
     ]
    }
   ],
   "source": [
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "num_attempts = 13\n",
    "\n",
    "random.seed(4815162352)\n",
    "batch_sizes = [int(np.round(2 ** random.uniform(5,8))) for i in range(num_attempts)]\n",
    "dropouts = [random.uniform(0,0.9) for i in range(num_attempts)]\n",
    "weight_decays = [np.exp(random.normalvariate(0,0.5)) for i in range(num_attempts)]\n",
    "stats = []\n",
    "fbs,fwd,fd = 0,0,0\n",
    "best_acc = -999\n",
    "\n",
    "disable = True\n",
    "epochs = 70\n",
    "every_other = 10\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "    batch_size = batch_sizes[i]\n",
    "    weight_decay = weight_decays[i]\n",
    "    dropout = dropouts[i]\n",
    "    print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "    for i in range(5):\n",
    "        torch.manual_seed(4815162342)\n",
    "        model = DeepRadarNet(dropout=dropout).cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        dlosscurve = []\n",
    "        dacccurve = []\n",
    "        vlosscurve = []\n",
    "        vacccurve = []\n",
    "        print(\"Fold %d\" % (i + 1))\n",
    "        my_data.setTest(i)\n",
    "        my_test.setTest(i)\n",
    "\n",
    "        my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        for j in range(epochs):\n",
    "            dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "            vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "            dlosscurve.append(dloss)\n",
    "            dacccurve.append(dacc)\n",
    "            vlosscurve.append(vloss)\n",
    "            vacccurve.append(vacc)\n",
    "            if j % every_other == every_other - 1:\n",
    "                print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "        df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "        df.plot.line()\n",
    "        avedloss += dloss\n",
    "        avedacc += dacc\n",
    "        avevloss += vloss\n",
    "        avevacc += vacc\n",
    "    avedloss /= 5\n",
    "    avedacc /= 0.05\n",
    "    avevloss /= 5\n",
    "    avevacc /= 0.05\n",
    "    if avevacc > best_acc:\n",
    "        fbs,fwd,fd,best_acc = batch_size, weight_decay, dropout, avevacc\n",
    "    print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "    print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\\nAverage Test Loss: {:.6f}\\nAverage Test Accuracy: {:.6f}\\n\".format(avedloss,avedacc,avevloss,avevacc))\n",
    "    stats.append([avedloss,avedacc,avevloss,avevacc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stats)):\n",
    "    print(\"{:.2f} & {:.2f} & {:.2f} & {} \\\\\\\\ \\\\hline\".format(batch_sizes[i],weight_decays[i],dropouts[i],\" & \".join([\"{:.2f}{}\".format(stats[i][j],\"\\\\%\" if j % 2 == 1 else \"\") for j in range(len(stats[i]))])))\n",
    "# hyperparameters\n",
    "batch_size = fbs\n",
    "weight_decay = fwd\n",
    "dropout = fd\n",
    "disable = False\n",
    "epochs = 100\n",
    "every_other = 10\n",
    "\n",
    "# initializing training objects\n",
    "torch.manual_seed(4815162342)\n",
    "model = DeepRadarNet(dropout=dropout).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# initializing dataset\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_val = AutoUXDataset(dataVal,labelsVal,False,True)\n",
    "my_loader = DataLoader(my_data, batch_size=batch_size,shuffle=True)\n",
    "my_val_loader = DataLoader(my_val, batch_size=batch_size,shuffle=True)\n",
    "my_data.setTest(-1)\n",
    "my_val.setTest(-1)\n",
    "\n",
    "# initializing tracking variables\n",
    "dlosscurve = []\n",
    "dacccurve = []\n",
    "vlosscurve = []\n",
    "vacccurve = []\n",
    "\n",
    "# training loop\n",
    "for j in range(epochs):\n",
    "    dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "    vloss, vacc = test(model,criterion,my_val_loader,disable)\n",
    "    dlosscurve.append(dloss)\n",
    "    dacccurve.append(dacc)\n",
    "    vlosscurve.append(vloss)\n",
    "    vacccurve.append(vacc)\n",
    "    if j % every_other == every_other - 1:\n",
    "        print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "\n",
    "print(\"Batch Size: {}\\nWeight Decay: {}\\nDropout: {}\\n\".format(batch_size,weight_decay,dropout))\n",
    "print(\"Train Loss: {:.6f}\\nTrain Accuracy: {:.6f}\\nValidation Loss: {:.6f}\\nValidation Accuracy: {:.6f}\\n\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "print(\"{} & {:.2f} & N/A & {:.2f} & {:.2f} & {:.2f}\\% & {:.2f} & {:.2f}\\% \\\\\\\\ \\\\hline\".format(batch_size,weight_decay,dropout,dloss,dacc * 100,vloss, vacc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.array([])\n",
    "preds = np.array([])\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(my_val,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model(x).cpu()\n",
    "        answers = np.append(answers,y_pred[:,1])\n",
    "        preds = np.append(preds,torch.max(y_pred,1)[1])\n",
    "answers = np.exp(answers)\n",
    "print(answers)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DeepRadarNetoutprobs.pt', 'wb') as f:\n",
    "    pickle.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "import pickle\n",
    "with open('DeepRadarNetout.pt', 'rb') as f:\n",
    "    y_pred = pickle.load(f)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "for x in labels:\n",
    "    y_test = np.append(y_test,x)\n",
    "\n",
    "class_names = [\"bad site\",\"good site\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "print(\"Accuracy: {:.4f}\".format(np.mean(y_test==y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
