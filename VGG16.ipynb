{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataconv.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labels.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self,dropout=0.5):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3)\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3)\n",
    "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3,padding=1)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(3072,4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 4)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv1(x)))\n",
    "        x = self.dropout(torch.relu(self.conv2(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv3(x)))\n",
    "        x = self.dropout(torch.relu(self.conv4(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv5(x)))\n",
    "        x = self.dropout(torch.relu(self.conv6(x)))\n",
    "        x = self.dropout(torch.relu(self.conv6(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv7(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.mp(x)\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = d + data[i];\n",
    "                l = l + labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc\n",
    "\n",
    "def test_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:14<00:00,  2.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 1.151829  Epoch Train Accuracy: 50.287829  Epoch Test Loss: 0.843656  Epoch Test Accuracy: 48.505435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.746913  Epoch Train Accuracy: 51.891447  Epoch Test Loss: 0.701716  Epoch Test Accuracy: 46.512681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.712867  Epoch Train Accuracy: 51.336349  Epoch Test Loss: 0.703742  Epoch Test Accuracy: 49.003623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.698333  Epoch Train Accuracy: 51.452851  Epoch Test Loss: 0.702628  Epoch Test Accuracy: 47.961957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.702865  Epoch Train Accuracy: 48.985746  Epoch Test Loss: 0.734831  Epoch Test Accuracy: 48.913043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.712461  Epoch Train Accuracy: 50.630482  Epoch Test Loss: 0.717429  Epoch Test Accuracy: 50.271739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.707230  Epoch Train Accuracy: 51.322643  Epoch Test Loss: 0.699166  Epoch Test Accuracy: 50.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.702993  Epoch Train Accuracy: 48.026316  Epoch Test Loss: 0.700897  Epoch Test Accuracy: 49.841486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.710174  Epoch Train Accuracy: 47.498629  Epoch Test Loss: 0.710361  Epoch Test Accuracy: 48.913043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.712628  Epoch Train Accuracy: 47.724781  Epoch Test Loss: 0.702470  Epoch Test Accuracy: 50.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.701049  Epoch Train Accuracy: 50.075384  Epoch Test Loss: 0.716330  Epoch Test Accuracy: 48.913043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.721919  Epoch Train Accuracy: 53.152412  Epoch Test Loss: 0.736455  Epoch Test Accuracy: 51.086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.725478  Epoch Train Accuracy: 49.403783  Epoch Test Loss: 0.711832  Epoch Test Accuracy: 50.475543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.705478  Epoch Train Accuracy: 46.628289  Epoch Test Loss: 0.697619  Epoch Test Accuracy: 54.415761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.704089  Epoch Train Accuracy: 50.712719  Epoch Test Loss: 0.700284  Epoch Test Accuracy: 52.966486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.713184  Epoch Train Accuracy: 48.588268  Epoch Test Loss: 0.733829  Epoch Test Accuracy: 50.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.704074  Epoch Train Accuracy: 50.322094  Epoch Test Loss: 0.698344  Epoch Test Accuracy: 48.709239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.699139  Epoch Train Accuracy: 52.796053  Epoch Test Loss: 0.707958  Epoch Test Accuracy: 50.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.699906  Epoch Train Accuracy: 53.063322  Epoch Test Loss: 0.704766  Epoch Test Accuracy: 50.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.702198  Epoch Train Accuracy: 48.978893  Epoch Test Loss: 0.715561  Epoch Test Accuracy: 50.475543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.703906  Epoch Train Accuracy: 51.158169  Epoch Test Loss: 0.703893  Epoch Test Accuracy: 48.278986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 0.701281  Epoch Train Accuracy: 49.067982  Epoch Test Loss: 0.701439  Epoch Test Accuracy: 48.075181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▌                                            | 11/24 [00:05<00:06,  2.08it/s]"
     ]
    }
   ],
   "source": [
    "avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "batch_size = 32\n",
    "disable = False\n",
    "epochs = 50\n",
    "dropout = 0.3\n",
    "weight_decay = 0.075\n",
    "\n",
    "for i in range(5):\n",
    "    model = VGG16(dropout=dropout).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "    #amp_handle.wrap_optimizer(optimizer)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #amp_handle = amp.init()\n",
    "    dlosscurve = []\n",
    "    dacccurve = []\n",
    "    vlosscurve = []\n",
    "    vacccurve = []\n",
    "    print(\"Fold %d\" % (i + 1))\n",
    "    my_data.setTest(i)\n",
    "    my_test.setTest(i)\n",
    "    \n",
    "    my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    for j in range(epochs):\n",
    "        dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "        vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "        dlosscurve.append(dloss)\n",
    "        dacccurve.append(dacc)\n",
    "        vlosscurve.append(vloss)\n",
    "        vacccurve.append(vacc)\n",
    "        if j % 1 == 0:\n",
    "            print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "    df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "    df.plot.line()\n",
    "    avedloss += dloss\n",
    "    avedacc += dacc\n",
    "    avevloss += vloss\n",
    "    avevacc += vacc\n",
    "avedloss /= 5\n",
    "avedacc /= 5\n",
    "avevloss /= 5\n",
    "avevacc /= 5\n",
    "print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\\nAverage Test Loss: {:.6f}\\nAverage Test Accuracy: {:.6f}\\n\".format(avedloss,avedacc,avevloss,avevacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXFullDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        super(AutoUXFullDataset,self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            d = d + data[i];\n",
    "            l = l + labels[i]\n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trainX)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avedloss, avedacc = 0,0\n",
    "my_data = AutoUXFullDataset(data,labels)\n",
    "\n",
    "batch_size = 32\n",
    "disable = False\n",
    "epochs = 50\n",
    "every_other = 1\n",
    "\n",
    "model = VGG16(0.5).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=0.1)\n",
    "#amp_handle.wrap_optimizer(optimizer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#amp_handle = amp.init()\n",
    "dlosscurve = []\n",
    "dacccurve = []\n",
    "\n",
    "my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "for j in range(epochs):\n",
    "    dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "    dlosscurve.append(dloss)\n",
    "    dacccurve.append(dacc)\n",
    "    if j % every_other == 0:\n",
    "        print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}\".format(dloss,dacc * 100))\n",
    "df = pd.DataFrame(data={\"train_loss\": dlosscurve})\n",
    "df.plot.line()\n",
    "avedloss += dloss\n",
    "avedacc += dacc\n",
    "print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\".format(avedloss,avedacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loader = DataLoader(my_data, batch_size=32,\n",
    "                        shuffle=False)\n",
    "answers = np.array([])\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(my_loader,disable=False):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model(x).cpu()\n",
    "        answers = np.append(answers,y_pred[:,1])\n",
    "answers = np.exp(answers)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('VGG16outprobs.pt', 'wb') as f:\n",
    "    pickle.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "import pickle\n",
    "with open('VGG16out.pt', 'rb') as f:\n",
    "    y_pred = pickle.load(f)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "for x in labels:\n",
    "    y_test = np.append(y_test,x)\n",
    "\n",
    "class_names = [\"bad site\",\"good site\"]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "print(\"Accuracy: {:.4f}\".format(np.mean(y_test==y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
