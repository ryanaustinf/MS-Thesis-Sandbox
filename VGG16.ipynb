{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n",
    "from random import shuffle\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataconv.pt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('labels.pt', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self,dropout=0.5):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3)\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3)\n",
    "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3,padding=1)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(3072,4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 4)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv1(x)))\n",
    "        x = self.dropout(torch.relu(self.conv2(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv3(x)))\n",
    "        x = self.dropout(torch.relu(self.conv4(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv5(x)))\n",
    "        x = self.dropout(torch.relu(self.conv6(x)))\n",
    "        x = self.dropout(torch.relu(self.conv6(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv7(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.mp(x)\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv8(x)))\n",
    "        x = self.dropout(torch.relu(self.conv9(x)))\n",
    "        x = self.mp(x)\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoUXDataset(Dataset):\n",
    "    def __init__(self, data, labels,isTrain=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.isTrain = isTrain\n",
    "        self.setTest(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.trainX)\n",
    "        else:\n",
    "            return len(self.testX)\n",
    "\n",
    "    def setTest(self,testI):\n",
    "        d = []\n",
    "        l = []\n",
    "        for i in range(5):\n",
    "            if i != testI:\n",
    "                d = d + data[i];\n",
    "                l = l + labels[i]\n",
    "            else:\n",
    "                self.testX = torch.from_numpy(np.asarray(data[i],dtype=np.uint8)).type('torch.FloatTensor')\n",
    "                self.testY = torch.from_numpy(np.asarray(labels[i],dtype=np.uint8)).type('torch.LongTensor')\n",
    "                \n",
    "        self.trainX = torch.from_numpy(np.asarray(d,dtype=np.uint8)).type('torch.FloatTensor')\n",
    "        self.trainY = torch.from_numpy(np.asarray(l,dtype=np.uint8)).type('torch.LongTensor')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            return {\"img\" : self.trainX[idx], \"label\": self.trainY[idx]}\n",
    "        else:\n",
    "            return {\"img\" : self.testX[idx], \"label\": self.testY[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model,crit,opt,x, y):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step() \n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def train(model,crit,opt,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    for s in tqdm(dataload,disable=disable):\n",
    "        x, y = s.values()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lo, acc = train_batch(model,crit,opt,x,y)\n",
    "        dloss += lo\n",
    "        dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc\n",
    "\n",
    "def test_batch(model,crit,x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    return loss.item(),torch.sum(torch.max(y_pred, 1)[1] == y).item() / len(y)\n",
    "\n",
    "def test(model,crit,dataload,disable=False):\n",
    "    # Training loop\n",
    "    dloss, dacc = 0,0\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(dataload,disable=disable):\n",
    "            x, y = s.values()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lo, acc = test_batch(model,crit,x,y)\n",
    "            dloss += lo\n",
    "            dacc += acc\n",
    "    dloss /= len(dataload)\n",
    "    dacc /= len(dataload)\n",
    "    return dloss,dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avedloss, avedacc, avevloss, avevacc = 0,0,0,0\n",
    "my_data = AutoUXDataset(data,labels,True)\n",
    "my_test = AutoUXDataset(data,labels,False)\n",
    "\n",
    "batch_size = 32\n",
    "disable = False\n",
    "epochs = 50\n",
    "dropout = 0.3\n",
    "weight_decay = 0.075\n",
    "\n",
    "for i in range(5):\n",
    "    model = VGG16(dropout=dropout).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4,weight_decay=weight_decay)\n",
    "    #amp_handle.wrap_optimizer(optimizer)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #amp_handle = amp.init()\n",
    "    dlosscurve = []\n",
    "    dacccurve = []\n",
    "    vlosscurve = []\n",
    "    vacccurve = []\n",
    "    print(\"Fold %d\" % (i + 1))\n",
    "    my_data.setTest(i)\n",
    "    my_test.setTest(i)\n",
    "    \n",
    "    my_loader = DataLoader(my_data, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    my_test_loader = DataLoader(my_test, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    for j in range(epochs):\n",
    "        dloss, dacc = train(model,criterion,optimizer,my_loader,disable)\n",
    "        vloss, vacc = test(model,criterion,my_test_loader,disable)\n",
    "        dlosscurve.append(dloss)\n",
    "        dacccurve.append(dacc)\n",
    "        vlosscurve.append(vloss)\n",
    "        vacccurve.append(vacc)\n",
    "        if j % 1 == 0:\n",
    "            print(\"Epoch Train Loss: {:.6f}  Epoch Train Accuracy: {:.6f}  Epoch Test Loss: {:.6f}  Epoch Test Accuracy: {:.6f}\".format(dloss,dacc * 100,vloss,vacc * 100))\n",
    "    df = pd.DataFrame(data={\"train_loss\": dlosscurve, \"val_loss\": vlosscurve})\n",
    "    df.plot.line()\n",
    "    avedloss += dloss\n",
    "    avedacc += dacc\n",
    "    avevloss += vloss\n",
    "    avevacc += vacc\n",
    "avedloss /= 5\n",
    "avedacc /= 5\n",
    "avevloss /= 5\n",
    "avevacc /= 5\n",
    "print(\"Average Train Loss: {:.6f}\\nAverage Train Accuracy: {:.6f}\\nAverage Test Loss: {:.6f}\\nAverage Test Accuracy: {:.6f}\\n\".format(avedloss,avedacc,avevloss,avevacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
